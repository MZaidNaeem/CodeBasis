{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dab637fa-8fc8-4db9-be68-11f72f35d1ef",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "You are a data scientist / AI engineer working on a binary classification problem. You have been provided with a dataset named **`\"mushroom_classification.csv\"`**, which includes various features of mushrooms to predict whether they are edible or poisonous. The dataset comprises the following columns:\n",
    "\n",
    "- `cap_diameter:` The diameter of the mushroom cap.\n",
    "- `cap_shape:` The shape of the mushroom cap, encoded as integers.\n",
    "- `gill_attachment:` The attachment of the gills, encoded as integers.\n",
    "- `gill_color:` The color of the gills, encoded as integers.\n",
    "- `stem_height:` The height of the mushroom stem.\n",
    "- `stem_width` The width of the mushroom stem.\n",
    "- `stem_color:` The color of the mushroom stem, encoded as integers.\n",
    "- `season:` The season when the mushroom was found, encoded as float.\n",
    "- `class:` The classification of the mushroom, where 0 indicates edible and 1 indicates poisonous.\n",
    "\n",
    "Your task is to use this dataset to build and evaluate a binary classification model to classify mushrooms as edible or poisonous. You will start with basic models and gradually move towards advanced models like Gradient Boosting. Finally, you will explore various parameters of the Gradient Boosting model to enhance performance.\n",
    "\n",
    "**Dataset credits:** Prisha Sawhney (https://www.kaggle.com/datasets/prishasawhney/mushroom-dataset/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bd3443-1dfb-423e-a352-ed4c467635d6",
   "metadata": {},
   "source": [
    "**Import Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16910661-4e73-4474-a003-e7b98a391352",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b417318-3bea-4581-a1dc-9f049055a2c3",
   "metadata": {},
   "source": [
    "### Task 1: Data Preparation and Exploration\n",
    "\n",
    "1. Import the data from the `\"mushroom_classification.csv\"` file and store it in a variable df.\n",
    "2. Display the number of rows and columns in the dataset.\n",
    "3. Display the first few rows of the dataset to get an overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a63849e-217e-4de0-acf4-b3bafc415424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns: (54035, 9)\n",
      "First few rows of the dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap_diameter</th>\n",
       "      <th>cap_shape</th>\n",
       "      <th>gill_attachment</th>\n",
       "      <th>gill_color</th>\n",
       "      <th>stem_height</th>\n",
       "      <th>stem_width</th>\n",
       "      <th>stem_color</th>\n",
       "      <th>season</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.807467</td>\n",
       "      <td>1545</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1461</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.807467</td>\n",
       "      <td>1557</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1371</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.612496</td>\n",
       "      <td>1566</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1261</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.787572</td>\n",
       "      <td>1566</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1305</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.711971</td>\n",
       "      <td>1464</td>\n",
       "      <td>11</td>\n",
       "      <td>0.943195</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cap_diameter  cap_shape  gill_attachment  gill_color  stem_height  \\\n",
       "0          1372          2                2          10     3.807467   \n",
       "1          1461          2                2          10     3.807467   \n",
       "2          1371          2                2          10     3.612496   \n",
       "3          1261          6                2          10     3.787572   \n",
       "4          1305          6                2          10     3.711971   \n",
       "\n",
       "   stem_width  stem_color    season  class  \n",
       "0        1545          11  1.804273      1  \n",
       "1        1557          11  1.804273      1  \n",
       "2        1566          11  1.804273      1  \n",
       "3        1566          11  1.804273      1  \n",
       "4        1464          11  0.943195      1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Import the data from the \"mushroom_classification.csv\" file and store it in a variable 'df'\n",
    "df = pd.read_csv(\"mushroom_classification.csv\")\n",
    "\n",
    "# Step 2: Display the number of rows and columns in the dataset\n",
    "print(\"Number of rows and columns:\", df.shape)\n",
    "\n",
    "# Step 3: Display the first few rows of the dataset to get an overview\n",
    "print(\"First few rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155cd929-a553-4a27-9cc0-7ee4115bcfea",
   "metadata": {},
   "source": [
    "### Task 2: Exploratory Data Analysis (EDA)\n",
    "\n",
    "1. Perform a group-by operation on the target class and calculate the mean of the following features: `cap_diameter, stem_height, and stem_width`.\n",
    "2. Visualize the distribution of these features using box plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa0539e2-7d51-4c43-8831-4484fc0b13b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap_diameter</th>\n",
       "      <th>stem_height</th>\n",
       "      <th>stem_width</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>633.064696</td>\n",
       "      <td>0.627374</td>\n",
       "      <td>1208.915189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>513.236293</td>\n",
       "      <td>0.867251</td>\n",
       "      <td>921.516563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cap_diameter  stem_height   stem_width\n",
       "class                                        \n",
       "0        633.064696     0.627374  1208.915189\n",
       "1        513.236293     0.867251   921.516563"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_analyze = ['cap_diameter', 'stem_height', 'stem_width']\n",
    "grouped = df.groupby('class')[features_to_analyze].mean()\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "800d3c15-32bf-4a3c-b0c2-59d2078d0fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Visualize the distribution of these features using box plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2ab061-c25f-4441-adb0-19f0ddebfaa8",
   "metadata": {},
   "source": [
    "### Task 3: Model Training Using Basic Models\n",
    "\n",
    "1. Select the features `(cap_diameter, cap_shape, gill_attachment, gill_color, stem_height, stem_width, stem_color, season)` and the target variable `(class)` for modeling.\n",
    "2. Split the data into training and test sets with a test size of 25%.\n",
    "3. Initialize and train a Logistic Regression model using the training data.\n",
    "4. Make predictions on the test set using the trained model.\n",
    "5. Evaluate the model using a classification report and print the report.\n",
    "6. Initialize and train a Decision Tree Classifier model using the training data.\n",
    "7. Make predictions on the test set using the trained model.\n",
    "8. Evaluate the model using a classification report and print the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca28e050-af95-48a0-8e69-c59e438a37e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Select the features and target variable for modeling\n",
    "X = df[[\"cap_diameter\", \"cap_shape\", \"gill_attachment\", \"gill_color\", \"stem_height\", \"stem_width\", \"stem_color\", \"season\"]]\n",
    "y = df[\"class\"]\n",
    "\n",
    "# Step 2: Split the data into training and test sets with a test size of 25%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5802ce9b-2018-43ed-9869-0bec1077405b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.55      0.57      6087\n",
      "           1       0.65      0.67      0.66      7422\n",
      "\n",
      "    accuracy                           0.62     13509\n",
      "   macro avg       0.61      0.61      0.61     13509\n",
      "weighted avg       0.62      0.62      0.62     13509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Initialize and train a Logistic Regression model using the training data\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Make predictions on the test set using the trained model\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate the model using a classification report and print the report\n",
    "report_lr = classification_report(y_test, y_pred_lr)\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(report_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0ee4a78-b5e3-4872-8b59-9ec37d508b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      6087\n",
      "           1       0.98      0.98      0.98      7422\n",
      "\n",
      "    accuracy                           0.98     13509\n",
      "   macro avg       0.98      0.98      0.98     13509\n",
      "weighted avg       0.98      0.98      0.98     13509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Initialize and train a Decision Tree Classifier model using the training data\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Make predictions on the test set using the trained model\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Step 8: Evaluate the model using a classification report and print the report\n",
    "report_dt = classification_report(y_test, y_pred_dt)\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(report_dt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bf4ec0-b8d5-41da-b636-5f06b0b66a2d",
   "metadata": {},
   "source": [
    "### Task 4: Model Training Using Gradient Boosting Classifier\n",
    "\n",
    "1. Initialize and train a Gradient Boosting Classifier model using the training data.\n",
    "2. Make predictions on the test set using the trained model.\n",
    "3. Evaluate the model using a classification report and print the report.\n",
    "4. Calculate and display the feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "242e67dd-e3e9-444b-a6e7-5352767cc229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      6087\n",
      "           1       0.90      0.89      0.89      7422\n",
      "\n",
      "    accuracy                           0.88     13509\n",
      "   macro avg       0.88      0.88      0.88     13509\n",
      "weighted avg       0.88      0.88      0.88     13509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Initialize and train a Gradient Boosting Classifier model using the training data\n",
    "gb_model = GradientBoostingClassifier()\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 2: Make predictions on the test set using the trained model\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# Step 3: Evaluate the model using a classification report and print the report\n",
    "report_gb = classification_report(y_test, y_pred_gb)\n",
    "print(\"Gradient Boosting Classification Report:\")\n",
    "print(report_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05020492-f728-4a92-bd2b-5b5e30413738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Calculate and display the feature importances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc96c15-d72c-4a4c-9c40-9ae93a41de00",
   "metadata": {},
   "source": [
    "### Task 5: Exploring Various Parameters in Gradient Boosting Classifier\n",
    "\n",
    "1. Train a Gradient Boosting model with the following parameters:\n",
    "    - learning_rate = 0.05\n",
    "    - n_estimators = 150\n",
    "    - max_depth=4\n",
    "    - min_samples_split = 3\n",
    "    - min_samples_leaf = 2\n",
    "\n",
    "Learn about these parameters here: [scikit-learn GradientBoostingClassifier Parameters](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "2. Evaluate the model using a classification report and print the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56402d3f-b721-4c94-bc8b-a724b27a5b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Train a Gradient Boosting model with specified parameters\n",
    "gb_params = {\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 150,\n",
    "    'max_depth': 4,\n",
    "    'min_samples_split': 3,\n",
    "    'min_samples_leaf': 2\n",
    "}\n",
    "gb_model_custom = GradientBoostingClassifier(**gb_params)\n",
    "gb_model_custom.fit(X_train, y_train)\n",
    "\n",
    "# Step 2: Make predictions on the test set using the trained model\n",
    "y_pred_gb_custom = gb_model_custom.predict(X_test)\n",
    "\n",
    "# Step 3: Evaluate the model using a classification report and print the report\n",
    "report_gb_custom = classification_report(y_test, y_pred_gb_custom)\n",
    "print(\"Gradient Boosting Classification Report with Custom Parameters:\")\n",
    "print(report_gb_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7cc9c3-1e3d-471d-aa0d-6244521ae0ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
